{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections import defaultdict\n",
    "from geoalchemy2.shape import to_shape\n",
    "from geoalchemy2.elements import WKTElement\n",
    "from sqlalchemy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_USER = 'nadai'\n",
    "PG_DBNAME = 'WWW'\n",
    "\n",
    "# Creating SQLAlchemy's engine to use\n",
    "engine = create_engine('postgresql://{user}@localhost:5432/{dbname}'.format(user=PG_USER, dbname=PG_DBNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = defaultdict(list)\n",
    "\n",
    "sql = text('SELECT i.pro_com::int, i.ace::int, c.name FROM istat_sezioni i INNER JOIN cities c ON i.pro_com = c.pro_com WHERE ace <> 0')\n",
    "result = engine.execute(sql)\n",
    "names = []\n",
    "CITIES = {}\n",
    "for r in result:\n",
    "    quarters[r[0]].append(r[1])\n",
    "    CITIES[r[2]] = r[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78. , 57. , 44.5, 34.5, 24.5, 14.5,  4.5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_intervals = [\n",
    "    [1919, 1945],\n",
    "    [1946, 1960],\n",
    "    [1961, 1970],\n",
    "    [1971, 1980],\n",
    "    [1981, 1990],\n",
    "    [1991, 2000],\n",
    "    [2001, 2010],\n",
    "]\n",
    "age_mean_intervals = []\n",
    "for low, high in age_intervals:\n",
    "    now = age_intervals[-1][1]\n",
    "    avg = float((now-low) + (now-high))/2.\n",
    "    age_mean_intervals.append(avg)\n",
    "age_mean_intervals = np.array(age_mean_intervals)\n",
    "age_mean_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "htypes_w = np.array([\n",
    "    1., 2., 3., 7.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "\n",
    "\n",
    "# Data conventions: A point is a pair of floats (x, y). A circle is a triple of floats (center x, center y, radius).\n",
    "\n",
    "# \n",
    "# Returns the smallest circle that encloses all the given points. Runs in expected O(n) time, randomized.\n",
    "# Input: A sequence of pairs of floats or ints, e.g. [(0,5), (3.1,-2.7)].\n",
    "# Output: A triple of floats representing a circle.\n",
    "# Note: If 0 points are given, None is returned. If 1 point is given, a circle of radius 0 is returned.\n",
    "# \n",
    "def make_circle(points):\n",
    "    # Convert to float and randomize order\n",
    "    shuffled = [(float(p[0]), float(p[1])) for p in points]\n",
    "    random.shuffle(shuffled)\n",
    "    \n",
    "    # Progressively add points to circle or recompute circle\n",
    "    c = None\n",
    "    for (i, p) in enumerate(shuffled):\n",
    "        if c is None or not _is_in_circle(c, p):\n",
    "            c = _make_circle_one_point(shuffled[0 : i + 1], p)\n",
    "    return c\n",
    "\n",
    "\n",
    "# One boundary point known\n",
    "def _make_circle_one_point(points, p):\n",
    "    c = (p[0], p[1], 0.0)\n",
    "    for (i, q) in enumerate(points):\n",
    "        if not _is_in_circle(c, q):\n",
    "            if c[2] == 0.0:\n",
    "                c = _make_diameter(p, q)\n",
    "            else:\n",
    "                c = _make_circle_two_points(points[0 : i + 1], p, q)\n",
    "    return c\n",
    "\n",
    "\n",
    "# Two boundary points known\n",
    "def _make_circle_two_points(points, p, q):\n",
    "    diameter = _make_diameter(p, q)\n",
    "    if all(_is_in_circle(diameter, r) for r in points):\n",
    "        return diameter\n",
    "    \n",
    "    left = None\n",
    "    right = None\n",
    "    for r in points:\n",
    "        cross = _cross_product(p[0], p[1], q[0], q[1], r[0], r[1])\n",
    "        c = _make_circumcircle(p, q, r)\n",
    "        if c is None:\n",
    "            continue\n",
    "        elif cross > 0.0 and (left is None or _cross_product(p[0], p[1], q[0], q[1], c[0], c[1]) > _cross_product(p[0], p[1], q[0], q[1], left[0], left[1])):\n",
    "            left = c\n",
    "        elif cross < 0.0 and (right is None or _cross_product(p[0], p[1], q[0], q[1], c[0], c[1]) < _cross_product(p[0], p[1], q[0], q[1], right[0], right[1])):\n",
    "            right = c\n",
    "    return left if (right is None or (left is not None and left[2] <= right[2])) else right\n",
    "\n",
    "\n",
    "def _make_circumcircle(p0, p1, p2):\n",
    "    # Mathematical algorithm from Wikipedia: Circumscribed circle\n",
    "    ax = p0[0]; ay = p0[1]\n",
    "    bx = p1[0]; by = p1[1]\n",
    "    cx = p2[0]; cy = p2[1]\n",
    "    d = (ax * (by - cy) + bx * (cy - ay) + cx * (ay - by)) * 2.0\n",
    "    if d == 0.0:\n",
    "        return None\n",
    "    x = ((ax * ax + ay * ay) * (by - cy) + (bx * bx + by * by) * (cy - ay) + (cx * cx + cy * cy) * (ay - by)) / d\n",
    "    y = ((ax * ax + ay * ay) * (cx - bx) + (bx * bx + by * by) * (ax - cx) + (cx * cx + cy * cy) * (bx - ax)) / d\n",
    "    return (x, y, math.hypot(x - ax, y - ay))\n",
    "\n",
    "\n",
    "def _make_diameter(p0, p1):\n",
    "    return ((p0[0] + p1[0]) / 2.0, (p0[1] + p1[1]) / 2.0, math.hypot(p0[0] - p1[0], p0[1] - p1[1]) / 2.0)\n",
    "\n",
    "\n",
    "_EPSILON = 1e-12\n",
    "\n",
    "def _is_in_circle(c, p):\n",
    "    return c is not None and math.hypot(p[0] - c[0], p[1] - c[1]) < c[2] + _EPSILON\n",
    "\n",
    "\n",
    "# Returns twice the signed area of the triangle defined by (x0, y0), (x1, y1), (x2, y2)\n",
    "def _cross_product(x0, y0, x1, y1, x2, y2):\n",
    "    return (x1 - x0) * (y2 - y0) - (y1 - y0) * (x2 - x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15146 30 0.011764705882352941\n",
      "4882782.768728021 1\n",
      "15146 48 0.023529411764705882\n",
      "1468225.217290009 1\n",
      "15146 28 0.03529411764705882\n",
      "2317991.566914328 1\n",
      "15146 20 0.047058823529411764\n",
      "566839.4661657303 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nadai/compiled/python3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py:141: RuntimeWarning: Mean of empty slice.\n",
      "/data/nadai/compiled/python3.6.4/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/data/nadai/compiled/python3.6.4/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15146 62 0.058823529411764705\n",
      "1531643.7663193343 1\n",
      "15146 80 0.07058823529411765\n",
      "2122626.45215954 1\n",
      "15146 8 0.08235294117647059\n",
      "1569740.7626129147 1\n",
      "15146 27 0.09411764705882353\n",
      "992474.0 1.0\n",
      "15146 26 0.10588235294117647\n",
      "911739.8713214269 1\n",
      "15146 25 0.11764705882352941\n",
      "744470.7072395597 1\n",
      "15146 82 0.12941176470588237\n",
      "1069624.488429317 1\n",
      "15146 66 0.1411764705882353\n",
      "1702065.287085221 1\n",
      "15146 33 0.15294117647058825\n",
      "1872249.6128425098 1\n",
      "15146 50 0.16470588235294117\n",
      "2214643.3773667812 1\n",
      "15146 17 0.17647058823529413\n",
      "798226.141109472 1\n",
      "15146 69 0.18823529411764706\n",
      "4485666.189943539 1\n",
      "15146 76 0.2\n",
      "3519366.679043402 1\n",
      "15146 31 0.21176470588235294\n",
      "1708071.136902785 1\n",
      "15146 51 0.2235294117647059\n",
      "1627942.981505203 1\n",
      "15146 57 0.23529411764705882\n",
      "732231.0 1\n",
      "15146 11 0.24705882352941178\n",
      "895630.5176194198 1\n",
      "15146 39 0.25882352941176473\n",
      "3767228.281249307 1\n",
      "15146 67 0.27058823529411763\n",
      "1250665.011401501 1\n",
      "15146 74 0.2823529411764706\n",
      "1528974.6870703143 1\n",
      "15146 64 0.29411764705882354\n",
      "1978631.674416746 1\n",
      "15146 84 0.3058823529411765\n",
      "1377785.3381300764 1\n",
      "15146 41 0.3176470588235294\n",
      "1410855.9895579782 1\n",
      "15146 71 0.32941176470588235\n",
      "1651479.9090482611 1\n",
      "15146 6 0.3411764705882353\n",
      "1506722.866692218 1\n",
      "15146 72 0.35294117647058826\n",
      "1876847.125108151 1\n",
      "15146 2 0.36470588235294116\n",
      "1644971.692882898 1\n",
      "15146 29 0.3764705882352941\n",
      "1964742.125017277 1\n",
      "15146 18 0.38823529411764707\n",
      "796014.058226265 1\n",
      "15146 42 0.4\n",
      "2050697.3611817337 1\n",
      "15146 59 0.4117647058823529\n",
      "771944.2714094222 1\n",
      "15146 81 0.4235294117647059\n",
      "853948.6204573917 1\n",
      "15146 34 0.43529411764705883\n",
      "1921716.3670040332 1\n",
      "15146 79 0.4470588235294118\n",
      "828526.0 0.999999849129659\n",
      "15146 10 0.4588235294117647\n",
      "1350167.3642697744 1\n",
      "15146 12 0.47058823529411764\n",
      "936987.0026719696 1\n",
      "15146 4 0.4823529411764706\n",
      "1587892.6257964591 1\n",
      "15146 77 0.49411764705882355\n",
      "2527379.261109805 1\n",
      "15146 73 0.5058823529411764\n",
      "4272489.559657483 1\n",
      "15146 46 0.5176470588235295\n",
      "2487101.8273682417 1\n",
      "15146 15 0.5294117647058824\n",
      "610659.9005705416 1\n",
      "15146 36 0.5411764705882353\n",
      "2235525.43573465 1\n",
      "15146 83 0.5529411764705883\n",
      "601311.2849846103 1\n",
      "15146 23 0.5647058823529412\n",
      "826933.0052396753 1\n",
      "15146 44 0.5764705882352941\n",
      "1963205.9279649733 1\n",
      "15146 53 0.5882352941176471\n",
      "2366364.69972521 1\n",
      "15146 56 0.6\n",
      "779154.0346778948 1\n",
      "15146 40 0.611764705882353\n",
      "3016923.035962317 1\n",
      "15146 16 0.6235294117647059\n",
      "771698.8618457317 1\n",
      "15146 54 0.6352941176470588\n",
      "1013154.8378222828 1\n",
      "15146 47 0.6470588235294118\n",
      "1330867.9362029203 1\n",
      "15146 60 0.6588235294117647\n",
      "921737.1087495266 1\n",
      "15146 45 0.6705882352941176\n",
      "1557392.5571852203 1\n",
      "15146 70 0.6823529411764706\n",
      "800789.9217726216 1\n",
      "15146 75 0.6941176470588235\n",
      "1085994.60495548 1\n",
      "15146 5 0.7058823529411765\n",
      "1536729.6613895874 1\n",
      "15146 21 0.7176470588235294\n",
      "535997.0 1\n",
      "15146 1 0.7294117647058823\n",
      "2280336.53165807 1\n",
      "15146 58 0.7411764705882353\n",
      "600239.0 1\n",
      "15146 22 0.7529411764705882\n",
      "1314918.2255249578 1\n",
      "15146 13 0.7647058823529411\n",
      "897751.1554963865 1\n",
      "15146 49 0.7764705882352941\n",
      "1032055.3340079859 1\n",
      "15146 14 0.788235294117647\n",
      "662393.0 1.0\n",
      "15146 52 0.8\n",
      "1859712.459340127 1\n",
      "15146 35 0.8117647058823529\n",
      "790008.0018013524 1\n",
      "15146 65 0.8235294117647058\n",
      "1399418.755649232 1\n",
      "15146 37 0.8352941176470589\n",
      "3501376.977402698 1\n",
      "15146 19 0.8470588235294118\n",
      "822340.178961317 1\n",
      "15146 43 0.8588235294117647\n",
      "2157303.3785812072 1\n",
      "15146 61 0.8705882352941177\n",
      "1367397.699559875 1\n",
      "15146 3 0.8823529411764706\n",
      "1226393.333313433 1\n",
      "15146 38 0.8941176470588236\n",
      "3510438.970101031 1\n",
      "15146 55 0.9058823529411765\n",
      "1403928.6366156382 1\n",
      "15146 68 0.9176470588235294\n",
      "1431021.0557937662 1\n",
      "15146 7 0.9294117647058824\n",
      "896771.412284046 1\n",
      "15146 78 0.9411764705882353\n",
      "1240128.2910383344 1\n",
      "15146 32 0.9529411764705882\n",
      "1732241.3927563354 1\n",
      "15146 85 0.9647058823529412\n",
      "1176058.9479899108 1\n",
      "15146 24 0.9764705882352941\n",
      "577697.3215273321 1\n",
      "15146 9 0.9882352941176471\n",
      "779468.0 0.999999679268424\n",
      "15146 63 1.0\n",
      "1756051.992477728 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import traceback\n",
    "\n",
    "\n",
    "columns=[('a', 'b')]\n",
    "results_df = pd.DataFrame({}, index=pd.MultiIndex.from_tuples(columns, names=['ace', 'pro_com']))\n",
    "#clean the dataframe\n",
    "results_df = results_df[results_df.index.get_level_values('ace') == 'Ras']\n",
    "try:\n",
    "    for city, pro_com in CITIES.items():\n",
    "        count = 0.0\n",
    "        \n",
    "        for city_section in quarters[pro_com]:\n",
    "            count += 1.0\n",
    "            print(pro_com, city_section, count/len(quarters[pro_com]))\n",
    "            \n",
    "            #\n",
    "            # Mixed land use\n",
    "            #\n",
    "            \n",
    "            #LUM5_single\n",
    "            sql = text(\"SELECT COALESCE(SUM(CASE WHEN code IN('11100', '11210', '11220', '11230', '11240', '11300') THEN ST_Area(v.geom) END), 0) as res_sum, \\\n",
    "COALESCE(SUM(CASE WHEN code IN('12100') THEN ST_Area(v.geom) END), 0) as com_sum,  \\\n",
    "COALESCE(SUM(CASE WHEN code IN('14100', '14200', '50000') THEN ST_Area(v.geom) END), 0) as oth_sum \\\n",
    "from atlas_sezioni v \\\n",
    "where v.ace = :neigh_id and v.pro_com = :city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            LUM5_single_stats = np.array(result.fetchone())\n",
    "            LUM5_single = stats.entropy(LUM5_single_stats)/np.log(len(LUM5_single_stats))\n",
    "            results_df.loc[(city_section, pro_com), \"LUM5_single\"] = LUM5_single\n",
    "            \n",
    "            assert(LUM5_single <= 1.0 and LUM5_single >= 0)\n",
    "            \n",
    "            # RNR_nres_area\n",
    "            sql = text('select SUM(res_area::real), SUM(nonres_area::real) \\\n",
    "from ( \\\n",
    "select SUM(\"E3\"::real)/SUM(\"E2\"::real) * ST_Area(geom) as res_area, \\\n",
    "(SUM(\"E2\"::real)-SUM(\"E3\"::real))/SUM(\"E2\"::real) * ST_Area(geom) as nonres_area, sez, ace \\\n",
    "from istat_indicatori i  \\\n",
    "inner join census_areas on ace = i.\"ACE\" and pro_com=i.\"PROCOM\" and sez=i.\"NSEZ\" \\\n",
    "where pro_com = :city_code \\\n",
    "group by geom, sez, ace \\\n",
    "having SUM(\"E2\"::real) > 0 \\\n",
    ") foo \\\n",
    "where ace = :neigh_id')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            RNR_nres = result.fetchone()\n",
    "            RNR_nres = 1- math.fabs((RNR_nres[0]-RNR_nres[1]) / (RNR_nres[0] + RNR_nres[1]))\n",
    "            results_df.loc[(city_section, pro_com), \"RNR_nres\"] = RNR_nres\n",
    "            \n",
    "            assert(RNR_nres <= 1.0 and RNR_nres >= 0)\n",
    "            \n",
    "            \n",
    "            # nig_rat_daily\n",
    "            sql = text(\"SELECT COALESCE(Count(distinct CASE WHEN category IN ('NightLife', 'Art-night') THEN venueid END), 0) as night_num,  \\\n",
    "COALESCE(Count(distinct CASE WHEN category IN ('daily-use', 'non-daily-use', 'Organized activity', 'Services', 'Schools', 'Offices', 'Cultural', 'Food') THEN venueid END), 0) as daily_num \\\n",
    "from foursquare_venues v  \\\n",
    "inner join istat_sezioni s on ST_Within(v.geom, s.geom) \\\n",
    "where s.ace = :neigh_id and s.pro_com = :city_code\", (city_section, pro_com))\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            result = result.fetchone()\n",
    "            nig_tot_places = float(result[0])\n",
    "            nig_rat_daily = 0\n",
    "            if result[1] != 0:\n",
    "                nig_rat_daily = float(result[0])/float(result[1])\n",
    "            results_df.loc[(city_section, pro_com), \"nig_rat_daily\"] = nig_rat_daily\n",
    "            \n",
    "            \n",
    "            \n",
    "            # hType_mix\n",
    "            sql = text('select SUM(\"E17\"::real), SUM(\"E18\"::real), SUM(\"E19\"::real), SUM(\"E20\"::real) from istat_indicatori where \"ACE\" = :neigh_id AND \"PROCOM\" = :city_code')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            hType_mix_stats = np.array(result.fetchone())\n",
    "            hType_mix = stats.entropy(hType_mix_stats)/np.log(len(hType_mix_stats))\n",
    "            \n",
    "            assert(hType_mix <= 1.0 and hType_mix >= 0)\n",
    "            \n",
    "            #print bld_entr_interiors\n",
    "            results_df.loc[(city_section, pro_com), \"hType_mix\"] = hType_mix\n",
    "            results_df.loc[(city_section, pro_com), \"hType_mix2\"] = np.average(htypes_w, weights=hType_mix_stats)\n",
    "            results_df.loc[(city_section, pro_com), \"hType_mix3\"] = np.average(htypes_w[:3], weights=hType_mix_stats[:3])\n",
    "            \n",
    "            # mdist_nres_daily\n",
    "            sql = text(\"SELECT AVG(ST_Distance_Sphere(ext.geom, (SELECT a.geom \\\n",
    "    from foursquare_venues as a \\\n",
    "    where a.category IN('daily-use', 'Food') \\\n",
    "    ORDER BY \\\n",
    "    a.geom <-> \\\n",
    "    (ext.geom) \\\n",
    "    LIMIT 1 \\\n",
    "    ) ) ) \\\n",
    "    from atlas_sezioni as ext \\\n",
    "    where ext.code IN('11100', '11210', '11220', '11230', '11240', '11300', '12100', '14200') and ext.ace = :neigh_id and ext.pro_com= :city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            mdist_nres_ndaily = result.fetchone()[0]\n",
    "            results_df.loc[(city_section, pro_com), \"mdist_nres_daily\"] = mdist_nres_ndaily\n",
    "            \n",
    "            # ratio_daily_nondaily\n",
    "            sql = text(\"SELECT COALESCE(Count(distinct CASE WHEN category IN ('Food','daily-use') THEN venueid END), 0) as daily_num,  \\\n",
    "COALESCE(Count(distinct CASE WHEN category IN ('non-daily-use', 'Organized activity') THEN venueid END), 0) as nondaily_num \\\n",
    "from foursquare_venues v  \\\n",
    "inner join istat_sezioni s on ST_Within(v.geom, s.geom) \\\n",
    "where s.ace = :neigh_id and s.pro_com = :city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            comm = result.fetchone()\n",
    "            ratio_daily_nondaily = 0\n",
    "            if (comm[1] + comm[0]) > 0:\n",
    "                ratio_daily_nondaily = float(comm[1])/float(comm[1] + comm[0])\n",
    "            results_df.loc[(city_section, pro_com), \"ratio_daily_nondaily\"] = ratio_daily_nondaily\n",
    "            \n",
    "            \n",
    "            \n",
    "            #\n",
    "            # Contact opportunities\n",
    "            #\n",
    "            \n",
    "            # total area of the section\n",
    "            sql = text(\"select ST_Area(geom::geography)::real from istat_sezioni where ace = :neigh_id AND pro_com= :city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            total_area = result.fetchone()[0]\n",
    "            results_df.loc[(city_section, pro_com), \"area\"] = total_area\n",
    "            \n",
    "            \n",
    "            # total area without rivers and parks\n",
    "            sql = text(\"Select area from atlas_area_novac a \\\n",
    "WHERE a.ace = :neigh_id and a.pro_com=:city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            area_to_subtract = result.fetchone()\n",
    "            total_area_without_parksrivers = total_area\n",
    "            if area_to_subtract:\n",
    "                total_area_without_parksrivers = total_area - area_to_subtract[0]\n",
    "            \n",
    "                assert(total_area_without_parksrivers > 0)\n",
    "                \n",
    "            results_df.loc[(city_section, pro_com), \"area_filtr\"] = total_area_without_parksrivers\n",
    "            \n",
    "            \n",
    "            results_df.loc[(city_section, pro_com), \"nig_rat_daily3\"] = float(nig_tot_places)/total_area_without_parksrivers\n",
    "            results_df.loc[(city_section, pro_com), \"den_nres_daily\"] = float(comm[0])/total_area_without_parksrivers\n",
    "            results_df.loc[(city_section, pro_com), \"den_nres_non-daily\"] = float(comm[1])/total_area_without_parksrivers\n",
    "            \n",
    "            \n",
    "            sql = text(\"select count(distinct v.venueid) as num_community_places \\\n",
    "from foursquare_venues v \\\n",
    "inner join istat_sezioni s on ST_Within(v.geom, s.geom) \\\n",
    "and s.ace = :neigh_id and s.pro_com = :city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            tot_places = float(result.fetchone()[0])\n",
    "            \n",
    "            \n",
    "            # num_community_places\n",
    "            sql = text(\"select count(distinct v.venueid) as num_community_places \\\n",
    "from foursquare_venues v \\\n",
    "inner join istat_sezioni s on ST_Within(v.geom, s.geom) \\\n",
    "where v.category IN('Parks and outside', 'Organized activity', 'Food', 'Shops') \\\n",
    "and s.ace = :neigh_id and s.pro_com = :city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            num_community_places = int(result.fetchone()[0])\n",
    "            results_df.loc[(city_section, pro_com), \"num_community_places\"] = num_community_places\n",
    "            results_df.loc[(city_section, pro_com), \"num_community_places_poi\"] = 0\n",
    "            if tot_places > 0:\n",
    "                results_df.loc[(city_section, pro_com), \"num_community_places_poi\"] = float(num_community_places)/tot_places\n",
    "            \n",
    "            \n",
    "            # sphi\n",
    "            sql = text(\"Select ST_AsText(g) \\\n",
    "from ( \\\n",
    "SELECT (ST_Dump(ST_Difference(sezione.geom, roads_buffered.geom))).geom as g  \\\n",
    "from istat_sezioni as sezione, roads_buffered \\\n",
    "where roads_buffered.ace = sezione.ace AND roads_buffered.pro_com = sezione.pro_com AND sezione.ace = :neigh_id AND sezione.pro_com= :city_code \\\n",
    ") as foo \\\n",
    "where ST_Area(g::geography) > 3000;\")\n",
    "            results = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            sphi_stats = []\n",
    "            for r in results:\n",
    "                p = to_shape(WKTElement(r[0]))\n",
    "                pts = np.array(p.exterior.coords)\n",
    "                # Stable version\n",
    "                mean_pts = np.mean(pts,0)\n",
    "                pts -= mean_pts\n",
    "                result = make_circle(pts)\n",
    "                coo = (result[0] + mean_pts[0], result[1] + mean_pts[1], result[2])\n",
    "                sphi = float(p.area / (math.pi*coo[2]**2))\n",
    "                assert (sphi <= 1.0)\n",
    "                sphi_stats.append(sphi)\n",
    "            sphi = np.array(sphi_stats).mean()\n",
    "            results_df.loc[(city_section, pro_com), \"sphi\"] = sphi\n",
    "            #print \"sphi finito\"\n",
    "            \n",
    "            # avg_block_area\n",
    "            sql = text(\"Select area::real \\\n",
    "from ( \\\n",
    "SELECT ST_Area( \\\n",
    "(ST_Dump(ST_Difference(sezione.geom, roads_buffered.geom))).geom::geography) as area \\\n",
    "from istat_sezioni as sezione, roads_buffered \\\n",
    "where roads_buffered.ace = sezione.ace AND roads_buffered.pro_com = sezione.pro_com AND sezione.ace = :neigh_id AND sezione.pro_com= :city_code \\\n",
    ") as foo \\\n",
    "where area > 3000;\")\n",
    "            results = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            areas = []\n",
    "            for r in results:\n",
    "                areas.append(r[0])\n",
    "            #avg_block_area = np.mean(stats.boxcox(areas, lmbda=(-0.32)))\n",
    "            avg_block_area = np.mean(np.log(areas))\n",
    "            #print avg_block_area, rat_block_area\n",
    "            results_df.loc[(city_section, pro_com), \"avg_block_area\"] = avg_block_area\n",
    "            \n",
    "            \n",
    "            # 2-ways intersections\n",
    "            sql = text(\"SELECT COUNT(*) as num_intersect FROM roads_2ways_sezioni \\\n",
    "WHERE ace = :neigh_id AND pro_com = :city_code\") \n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            num_intersect = int(result.fetchone()[0])\n",
    "            \n",
    "            # roundabout 2-ways intersections\n",
    "            sql = text(\"select num, numd from roads_roundabout_sezioni \\\n",
    "WHERE ace = :neigh_id AND pro_com = :city_code\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            for r in result.fetchall():\n",
    "                num_intersect += int((r[1] +1))\n",
    "            \n",
    "            results_df.loc[(city_section, pro_com), \"num_intersect\"] = num_intersect\n",
    "            \n",
    "            #\n",
    "            # Aged buildings and enterprises\n",
    "            #\n",
    "            \n",
    "            # bld_entr_age\n",
    "            sql = text('select SUM(\"E8\"::real), SUM(\"E9\"::real), SUM(\"E10\"::real), SUM(\"E11\"::real), SUM(\"E12\"::real), SUM(\"E13\"::real), SUM(\"E14\"::real), (SUM(\"E15\"::real)+SUM(\"E16\"::real)) from istat_indicatori where \"ACE\" = :neigh_id AND \"PROCOM\" = :city_code')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            buildings_age_stats = np.array(result.fetchone())\n",
    "            bld_entr_age = stats.entropy(buildings_age_stats)/np.log(len(buildings_age_stats))\n",
    "            \n",
    "            assert(bld_entr_age <= 1.0 and bld_entr_age >= 0)\n",
    "            \n",
    "            #print bld_entr_age\n",
    "            results_df.loc[(city_section, pro_com), \"bld_entr_age\"] = bld_entr_age\n",
    "            \n",
    "            #ref: http://math.stackexchange.com/questions/320441/standard-deviation-of-the-weighted-mean\n",
    "            age_mean = np.average(age_mean_intervals, weights=buildings_age_stats[1:])\n",
    "            age_std_w = math.sqrt(age_mean_intervals.var() * (np.sum(np.power(buildings_age_stats[1:], 2))) / (np.power(np.sum(buildings_age_stats[1:]), 2)))\n",
    "            \n",
    "            results_df.loc[(city_section, pro_com), \"bld_avg_age\"] = age_mean\n",
    "            results_df.loc[(city_section, pro_com), \"bld_std_age\"] = age_std_w\n",
    "            \n",
    "            \n",
    "            # bld_entr_interiors\n",
    "            sql = text('select SUM(\"E21\"::real), SUM(\"E22\"::real), SUM(\"E23\"::real), SUM(\"E24\"::real), SUM(\"E25\"::real), SUM(\"E26\"::real) from istat_indicatori where \"ACE\" = :neigh_id AND \"PROCOM\" = :city_code')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            buildings_int_stats = np.array(result.fetchone())\n",
    "            bld_entr_interiors = stats.entropy(buildings_int_stats)\n",
    "            \n",
    "            #print bld_entr_interiors\n",
    "            results_df.loc[(city_section, pro_com), \"bld_entr_interiors\"] = bld_entr_interiors\n",
    "            \n",
    "            # enterprises_entr_size\n",
    "            # 4 dimensions of companies => entropy\n",
    "            sql = text('select count(*)::int \\\n",
    "from companies c \\\n",
    "inner join istat_sezioni sezione ON ST_Within(c.geom, sezione.geom) \\\n",
    "where dimension <> \\'n.d.\\' AND sezione.ace = :neigh_id and sezione.pro_com=:city_code \\\n",
    "group by dimension order by dimension')\n",
    "            results = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            enterprises_stats = []\n",
    "            for r in results:\n",
    "                enterprises_stats.append(r[0])\n",
    "            enterprises_entr_size = stats.entropy(enterprises_stats)\n",
    "            \n",
    "            #print enterprises_entr_size\n",
    "            results_df.loc[(city_section, pro_com), \"enterprises_entr_size\"] = enterprises_entr_size\n",
    "            \n",
    "            \n",
    "            sql = text('select AVG(\"ADDETTI\"::real) as average_size \\\n",
    "from istat_industria where \"NSEZ\" IN(select sez::int from census_areas where ace = :neigh_id and pro_com = :city_code) \\\n",
    "and \"PROCOM\" = :city_code')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            avg_entr = result.fetchone()[0]\n",
    "            \n",
    "            results_df.loc[(city_section, pro_com), \"enterprises_empl_size\"] = avg_entr\n",
    "            \n",
    "            \n",
    "            #\n",
    "            # Density\n",
    "            #\n",
    "\n",
    "            # pop_rat_num, emp_rat_num, emp_rat_pop, bld_rat_int\n",
    "            sql = text('select SUM(\"P1\"::real)/:area as pop_rat_num, \\\n",
    "            SUM(\"E27\"::real)/SUM(\"E3\"::real) as bld_rat_int from istat_indicatori where \"ACE\" = :neigh_id AND \"PROCOM\" = :city_code')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com, area=total_area_without_parksrivers)\n",
    "            pop_rat_num, bld_rat_int = result.fetchone()\n",
    "            #print pop_rat_num\n",
    "            assert(pop_rat_num <= 1.0)\n",
    "            assert(bld_rat_int >= 1.0)\n",
    "            results_df.loc[(city_section, pro_com), \"pop_rat_num\"] = pop_rat_num\n",
    "            results_df.loc[(city_section, pro_com), \"bld_rat_int\"] = bld_rat_int\n",
    "            \n",
    "            # emp_rat_num, emp_rat_pop\n",
    "            sql = text('select SUM(\"ADDETTI\"::real)/:area as emp_rat_num \\\n",
    "            from istat_industria where \"NSEZ\" IN(select sez::int from census_areas where ace = :neigh_id and pro_com = :city_code) \\\n",
    "            and \"PROCOM\" = :city_code')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com, area=total_area_without_parksrivers)\n",
    "            emp_rat_num = result.fetchone()[0]\n",
    "            emp_rat_pop = pop_rat_num/emp_rat_num\n",
    "            \n",
    "            assert(emp_rat_num <= 1.0)\n",
    "            \n",
    "            results_df.loc[(city_section, pro_com), \"emp_rat_pop\"] = emp_rat_pop\n",
    "            results_df.loc[(city_section, pro_com), \"emp_rat_num\"] = emp_rat_num\n",
    "            \n",
    "            \n",
    "            # bld_rat_area\n",
    "            sql = text('select sum(a.area::real)/:area as bld_rat_area from  \\\n",
    "(Select ST_Area(( \\\n",
    "CASE WHEN ST_CoveredBy(buildings_sezioni.geom, s.geom) THEN buildings_sezioni.geom ELSE ST_Multi(ST_Intersection(buildings_sezioni.geom,s.geom)) END)::geography) as area \\\n",
    "from buildings_sezioni \\\n",
    "inner join istat_sezioni s ON s.ace = buildings_sezioni.ace AND s.pro_com = buildings_sezioni.pro_com \\\n",
    "where buildings_sezioni.ace = :neigh_id and buildings_sezioni.pro_com=:city_code) as a')\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com, area=total_area_without_parksrivers)\n",
    "            bld_rat_area = result.fetchone()[0]\n",
    "            \n",
    "            # Fix precision errors\n",
    "            if bld_rat_area > 1:\n",
    "                bld_rat_area = 1\n",
    "            \n",
    "            #print bld_rat_area\n",
    "            results_df.loc[(city_section, pro_com), \"bld_rat_area\"] = bld_rat_area\n",
    "            \n",
    "            \n",
    "            #\n",
    "            # Border vacuums\n",
    "            #\n",
    "            \n",
    "            # bor_rat_area\n",
    "            sql = text(\"Select COALESCE(SUM(ST_Area(ST_intersection(a.geom, s.geom)::geography)), 0) from atlas_sezioni a \\\n",
    "inner join istat_sezioni s ON s.ace = a.ace AND s.pro_com = a.pro_com \\\n",
    "WHERE a.ace = :neigh_id and a.pro_com=:city_code AND a.code IN ('12210', '50000', '12230');\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            bor_rat_area = result.fetchone()[0]\n",
    "            \n",
    "            sql = text(\"Select COALESCE(SUM(ST_Area(ST_intersection(a.geom, s.geom)::geography)), 0) from parks a \\\n",
    "inner join istat_sezioni s ON ST_Intersects(a.geom, s.geom) \\\n",
    "WHERE s.ace = :neigh_id and s.pro_com=:city_code AND a.geoarea > 100000 and ST_isvalid(a.geom)\")\n",
    "            result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "            parks_area = result.fetchone()[0]\n",
    "            bor_rat_area = (bor_rat_area + parks_area)/total_area\n",
    "            \n",
    "            results_df.loc[(city_section, pro_com), \"bor_rat_area\"] = bor_rat_area\n",
    "            \n",
    "            if bor_rat_area > 1.0:\n",
    "                bor_rat_area = 1.0\n",
    "            \n",
    "            \n",
    "            vacuums = {\"mdist_railways\": 12230, \"mdist_parks\": 14100, \"mdist_highways\": 12210, \"mdist_water\": 50000, \"mdist_smallparks\": 3}\n",
    "            for k, v in vacuums.items():\n",
    "                if k in {\"mdist_highways\", \"mdist_water\"}:\n",
    "                    sql = text(\"select avg(dist) as d_avg \\\n",
    "from( \\\n",
    "\tSELECT dist, ROW_NUMBER() OVER (PARTITION BY g1 order by dist) AS r \\\n",
    "\tfrom ( select a.geom as g1, ST_DistanceSphere(a.geom, b.geom) as dist \\\n",
    "\t\tFROM atlas_sezioni a, \\\n",
    "\t\tLATERAL ( select vacuum.geom \\\n",
    "\t\t\tFROM atlas_sezioni vacuum \\\n",
    "\t\t\tWHERE a.pro_com = vacuum.pro_com AND vacuum.code = ':vacuum_code' \\\n",
    "\t\t\tORDER BY vacuum.geom <-> a.geom \\\n",
    "\t\t\tLIMIT 30 \\\n",
    "\t\t) b \\\n",
    "\t\tWHERE a.pro_com = :city_code and a.ace = :neigh_id AND a.code IN('11100', '11210', '11220', '11230', '11240', '11300', '12100', '14200') \\\n",
    "\t) odtable  \\\n",
    ") x WHERE x.r = 1;\")\n",
    "                    result = engine.execute(sql, neigh_id=city_section, city_code=pro_com, vacuum_code=v)\n",
    "                elif k == \"mdist_railways\":\n",
    "                    sql = text(\"select avg(dist) as d_avg \\\n",
    "from( \\\n",
    "\tSELECT dist, ROW_NUMBER() OVER (PARTITION BY g1 order by dist) AS r \\\n",
    "\tfrom ( select a.geom as g1, ST_DistanceSphere(a.geom, b.geom) as dist \\\n",
    "\t\tFROM atlas_sezioni a, \\\n",
    "\t\tLATERAL ( select vacuum.geom \\\n",
    "\t\t\tFROM atlas_railways vacuum \\\n",
    "\t\t\tWHERE a.pro_com = vacuum.pro_com \\\n",
    "\t\t\tORDER BY vacuum.geom <-> a.geom \\\n",
    "\t\t\tLIMIT 30 \\\n",
    "\t\t) b \\\n",
    "\t\tWHERE a.pro_com = :city_code and a.ace = :neigh_id AND a.code IN('11100', '11210', '11220', '11230', '11240', '11300', '12100', '14200') \\\n",
    "\t) odtable \\\n",
    ") x WHERE x.r = 1;\")\n",
    "                    result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "                elif k == \"mdist_smallparks\":\n",
    "                    sql = text(\"SELECT AVG(ST_DistanceSphere(ext.geom, (SELECT a.geom \\\n",
    "    from parks as a \\\n",
    "    where a.geoarea <= 10000 \\\n",
    "    ORDER BY \\\n",
    "    a.geom <#> \\\n",
    "    (ext.geom) \\\n",
    "    LIMIT 1 \\\n",
    "    ) ) ) \\\n",
    "    from atlas_sezioni as ext \\\n",
    "    where ext.code IN('11100', '11210', '11220', '11230', '11240', '11300', '12100', '14200') and ext.ace = :neigh_id and ext.pro_com = :city_code\")\n",
    "                    result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "                else:\n",
    "                    sql = text(\"SELECT AVG(ST_DistanceSphere(ext.geom, (SELECT a.geom \\\n",
    "    from parks as a \\\n",
    "    where a.geoarea > 100000  and ST_isvalid(a.geom) \\\n",
    "    ORDER BY \\\n",
    "    a.geom <-> \\\n",
    "    (ext.geom) \\\n",
    "    LIMIT 1 \\\n",
    "    ) ) ) \\\n",
    "    from atlas_sezioni as ext \\\n",
    "    where ext.code IN('11100', '11210', '11220', '11230', '11240', '11300', '12100', '14200') and ext.ace = :neigh_id and ext.pro_com=:city_code\")\n",
    "                    result = engine.execute(sql, neigh_id=city_section, city_code=pro_com)\n",
    "                \n",
    "                results_df.loc[(city_section, pro_com), k] = result.fetchone()[0]\n",
    "            \n",
    "except:\n",
    "    raise Exception(\"\".join(traceback.format_exception(*sys.exc_info())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('generated_files/computed_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
